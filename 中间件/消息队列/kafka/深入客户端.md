# 深入客户端

## 分区分配策略

kafka提供了消费者客户端参数`partition.assignment.strategy`来设置消费者与订阅主题之间的分区分配策略。

默认情况下此参数的值为`org.apache.kafka.clients.consumer.RangeAssignor`,除此之外，kafka还提供另外两种分配策略：RoundRobinAssignor和StickyAssignor，消费者客户端参数可以配置多个分配策略，彼此之间以逗号分隔开

### RangeAssignor分配策略

按照消费者总数和分区总数进行除整运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。

对于每一个主题，RangeAssignor策略会将消费组内所有订阅这个主题的消费者按照名称的字典序排序，然后为每个消费者划分固定的分区范围，如果不够平均分配，那么字典序靠前的消费者会被多分配一个分区。

分配不均的情况：

当有两个消费者，存在两个主题而且都是三个分区，那么根据该分配策略可以得出下面的结果。
因为三个分区无法被平均分配到两个消费者，多出来的分区会被分配到字典序靠前的消费者，所以两个主题的第三个分区都会被分配给字典序靠前的消费者consumer0，导致consumer0被分配到了4个分区，而consumer1只能被分配到2个分区。

consumer0: topic_0_partition_0，topic_0_partition_2, topic_1_partition_0, topic_1_partition_2
consumer1: topic_0_partition_1, topic_1_partition_1

### RoundRobinAssignor分配策略

将消费组内所有消费者及消费者订阅的所有主题的分区按照字典序排序，然后通过轮询方式逐个将分区依次分配给每个消费者。

比如说，消费者组中有2个消费者C0和C1，都订阅了主题t0和t1，每个主题都有3个分区，那么订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2

那么此时轮询上面的所有分区给2个消费者

C1: t0p0, t0p2,t1p1

C2: t0p1, t1p0,t1p2

分配不均的情况：

如果同一个消费者组内的消费者订阅的信息是不相同的话，有可能导致分区分配不均匀。

比如说消费组内有3个消费者，（C0, C1, C2）这3个主题分别有1、2、3个分区，即整个消费组订阅了t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区

具体而言，消费者C0订阅的是主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2

如果按照该分配策略，可以得到如下分配结果：

C0：t0p0, 
C1：t1p0, 
C2：t1p1, t2p0, t2p1, t2p2

可以看出下面的分配结果也不是最优解，因为C1也订阅了t1，完全可以把t1分配给C1

### StickyAssignor分配策略

该分配策略的主要两个目的：

1. 分区的分配要尽可能均匀
2. 分区的分配尽可能与上次分配的保持相同

当两者发生冲突时，第一个目标优先于第二个目标。

## 消费者协调器和组协调器

消费者协调器和组协调器完成多个消费者之间的分区分配的协调操作。

### 再均衡的原理

将全部消费组分成多个子集，每个消费组的子集在服务端对应一个GroupCoordinator对其进行管理，GroupCoordinator是kafka服务端中用于管理消费组的组件。而消费者客户端中的ConsumerCoordinator组件负责与GroupCoordinator进行交互。

触发再均衡的几种情况

- 有新的消费者加入消费组
- 有消费者宕机下线
- 有消费者主动退出消费组
- 消费组所对应的GroupCoorinator节点发生了变更
- 消费组内所订阅的任一主题或者主题的分区数量发生变化

#### 当有消费者加入消费组的情况

1. 第一阶段（FIND_COORDINATOR）

消费者向集群负载最小的broker发送FindCoordinatorRequest请求来查找GroupCoordinator。

kafka收到请求之后根据coordinator(groupId)查找对应的GroupCoordinator节点之后返回相对应的node_id,host,port信息。

先根据topic找到对应的partition，再找出对应分区的leader副本节点，该节点即为GroupCoordinator节点

2. 第二阶段（JOIN_GROUP）

在成功找到GroupCoordinator之后就到了加入消费组阶段，再此阶段消费者会向GroupCoordinator发送JoinGroupRequest请求

JoinGroupRequest包含几个field

- group_id，消费组id
- session_timeout，对应消费端参数`session.timeout.ms`，GroupCoordinator超过session_timeout指定的时间没有收到心跳则认为消费者下线
- rebalance_timeout， 对应消费端参数`max.poll.interval.ms`默认5分钟。表示当消费组再平衡的时候，GroupCoordinator等待各个消费者重新加入的最长等待时间
- member_id，表示GroupCoordinator分配给消费者的id标识；消费第一次发送JoinGroupRequest请求是此字段为null
- protocol_type，标识消费组实现的协议，对于消费者而言此字段值为”consumer“
- group_protocols，为数组类型；类型为{protocol_name, protocol_metadata}，protocol_metadata字段为{version,topics,user_data}

如果是原有的消费者重新加入消费组的话，再真正发送JoinGroupRequest请求之前还要执行一些准备工作

1. 如果消费端参数`enable.auto.commit`为true的话，需要请求加入消费组之前提交位移
2. 如果消费者添加了自定义的再均衡监听器（ConsumerRebalanceListener），会调用onPartitionsRevoked()方法
3. 禁止心跳检测的运作，因为是重新加入消费组，与之前的GroupCoordinator之间的心跳就不需要了

#### 选举消费组的leader

两种情况

- 如果消费组内没有leader，那么第一个加入消费组的消费者即为消费组的leader
- 如果leader退出了消费组，会重新选举一个新的leader，hashmap中的第一个消费者

#### 选举分区分配策略

每个消费者都可以设置自己的分区分配策略，而分区分配的选举并非由leader消费者决定，而是根据消费组内的各个消费者投票决定。

> “根据组内的各个消费者投票来决定”不是指GroupCoordinator 还要再与各个消费者进行进一步交互，而是根据各个消费者呈报的分配策略来实施。

1. 收集各个消费者支持的所有分配策略，组成候选集candidates（支持的所有分配策略指的是`partition.assignment.strategy`参数配置得策略）
2. 每个消费者从候选集candidates中找出第一个自身支持的策略，为这个策略投上一票
3. 计算候选集中各个策略的选票数，选票数最多的策略即为当前消费组的分配策略

![image-20210927113901339](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210927113901339.png)

![image-20210927113911321](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210927113911321.png)

3. 第三阶段（SYNC_GROUP）

leader 消费者根据在第二阶段中选举出来的分区分配策略来实施具体的分区分配，在此之后需要将分配的方案同步给各个消费者，此时leader消费者并不是直接和其余的普通消费者同步分配方案，而是通过 GroupCoordinator 这个“中间人”来负责转发同步分配方案的。在第三阶段，也就是同步阶段，各个消费者会向GroupCoordinator发送SyncGroupRequest请求来同步分配方案

![image-20210927114013557](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210927114013557.png)



服务端收到SyncGroupRequest之后会交由GroupCoordinator负责具体的逻辑处理。

在对SyncGroupRequest参数合法性校验完成后，会将从leader消费者发送过来的分配方案提取出来，连同整个消费组的元数据信息一起存入kafka的__consumer_offsets主题中，最后发送响应给各个消费者以提供给各个消费者各自所属的分配方案。

当消费者收到所属的分配方案之后会调用PartitionAssignor中的onAssignment（）方法。随后再调用ConsumerRebalanceListener中的OnPartitionAssigned（）方法。之后开启心跳任务，消费者定期向服务端的GroupCoordinator发送HeartbeatRequest来确定彼此在线。

#### 消费组元数据信息

我们知道消费者客户端提交的消费位移会保存在Kafka的__consumer_offsets主题中，消费组也差不多吧

4. 第四阶段（HEARTBEAT）

进入这个阶段之后，消费组中的所有消费者就会处于正常工作状态，在正式消费之前，消费者还需要确定拉取消息的起始位置。

消费者可以通过OffsetFetchRequest获取上次提交的位移并从此处继续消费。

心跳线程是一个独立的线程，可以在轮询消息的空档发送心跳。

如果消费者停止发送心跳的时间足够长，则整个会话就被判定为过期，GroupCoordinator 也会认为这个消费者已经死亡，就会触发一次再均衡行为。

消费者的心跳间隔时间由参数`heartbeat.interval.ms`指定，默认值为3000，即3秒，这个参数必须比`session.timeout.ms`参数设定的值要小，一般情况下heartbeat.interval.ms的配置值不能超过session.timeout.ms配置值的1/3。这个参数可以调整得更低，以控制正常重新平衡的预期时间。

## __consumer_offsets剖析

位移提交的内容最终会保存到Kafka的内部主题__consumer_offsets中

客户端提交消费位移是使用OffsetCommitRequest请求实现的

![image-20210928111814071](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210928111814071.png)

- retention_time表示当前提交的消费位移所能保留的时长，不过对于消费者而言这个值保持为-1；是按照broker端的配置`offsets.retention.minutes`来确定保留时长的，默认为10080，即7天。超过这个时间消费位移的信息就会被删除

## 事务

### 消息传输保障

消息中间件的消息传输保障有三个层级

1. at most once: 至多一次。消息可能会丢失，但绝对不会重复传输
2. at least once: 至少一次。消息绝对不会丢失，但可能会重复传输
3. exactly once: 恰好一次。每条消息肯定会被传输一次且仅传输一次

kafka一点消息被成功提交到日志文件，由于多副本机制的存在，会认为这条消息不会丢失

如果发送到kafka之后网络通信中断，生产者可以进行多次重试来确保写入kafka，重试过程可能导致消息重复写入，所以kafka提供的消息传输保障为at least once

### 幂等

开启幂等性功能，只需要将生产者客户端参数`enable.idempotence`设置为true

不过如果要确保幂等性功能正常，还需要确保生产者客户端的 `retries`、`acks`、`max.in.flight.requests.per.connection`这几个参数不被配置错。实际上在使用幂等性功能的时候，用户完全可以不用配置（也不建议配置）这几个参数。

- `retries`要大于0
- `acks`要为-1或为all
- `max.in.flight.requests.per.connection`不能大于5

为了实现生产者的幂等性，kafka引入了**producer id**（下面简称PID）和**序列号(sequence numbser)**两个概念

对于每个PID，消息发送到每一个分区都有对应的序列号，序列号从0开始单调递增。生产者每发送一条消息就会将＜PID，分区＞对应的序列号的值加1

broker端会在内存中为每一对＜PID，分区＞维护一个序列号，只有当它的序列号的值（SN_new）比broker端中维护的对应的序列号的值（SN_old）大1（即SN_new=SN_old+1）时，broker才会接收它。

Kafka的幂等只能保证单个生产者会话（session）中单分区的幂等。

### 事务

幂等性不能跨多个分区运作，而事务可以弥补这个缺陷。事务可以保证对多个分区写入操作的原子性。操作的原子性是指多个操作要么全部成功，要么全部失败，不存在部分成功、部分失败的可能。

为了实现事务，应用程序必须提供唯一的transactionalId，这个 transactionalId通过客户端参数transactional.id来显式设置。

```java
properties.put("transactional.id", "transactionId")
```

事务要求生产者开启幂等特性

为了保证新的生产者启动后具有相同transactionalId的旧生产者能够立即失效，每个生产者通过transactionalId获取PID的同时，还会获取一个单调递增的producer epoch。如果使用同一个transactionalId开启两个生产者，那么前一个生产者会报错。

在消费端有一个参数`isolation.level`取值

- `read_uncommitted` 消费端可以消费到未提交的事务
- `read_committed`消费端不可以看到尚未提交的事务内的消息

日志文件中除了普通的消息，还有一种消息专门用来标志一个事务的结束，它就是控制消息（ControlBatch）。控制消息一共有两种类型：COMMIT和ABORT，分别用来表征事务已经成功提交或已经被成功中止

![image-20210928153230490](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210928153230490.png)

为实现事务的功能，kafka引入了事务协调器（TransactionCoordinator）来负责处理事务。

每一个生产者都会被指派一个特定的TransactionCoordinator，所有的事务逻辑包括分派PID等都是由TransactionCoordinator来负责实施。TransactionCoordinator 会将事务状态持久化到内部主题__transaction_state 中。

![image-20210928153636912](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210928153636912.png)

1. 查找TransactionCoordinator；负责分配PID和管理事务。kafka收到FindCoordinator请求之后，会根据coordinator_key(transactionalId)查找对应的TransactionCoordinator节点
2. 获取Producer Id(PID)；生产者获取PID的操作是通过InitProducerIdRequest请求来实现的
   1. 保存PID；当TransactionCoordinator第一次收到包含该transactionalId的InitProducerIdRequest请求时，它会把transactionalId和对应的PID以消息（我们习惯性地把这类消息称为“事务日志消息”）的形式保存到主题__transaction_state中。
3. 开启事务；通过KafkaProducer的beginTransaction（）方法可以开启一个事务，调用该方法后，生产者本地会标记已经开启了一个新的事务，只有在生产者发送第一条消息之后 TransactionCoordinator才会认为该事务已经开启。
4. Consume-Transform-Produce
   1. 当生产者给一个新的分区（TopicPartition）发送数据前，它需要先向TransactionCoordinator发送AddPartitionsToTxnRequest请求

