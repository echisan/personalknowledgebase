# 可靠性探究



## 副本剖析

### 失效的副本

通过broker端唯一参数`replica.lag.time.max.ms`来抉择，默认值为10000；

![image-20210929145330699](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210929145330699.png)

当follower副本将leader副本LEO（LogEndOffset）之前的日志全部同步时，可以认为该follower副本已经追赶上leader副本，此时更新该副本的lastCaughtUpTimeMs标识。

Kafka 的副本管理器会启动一个副本过期检测的定时任务，而这个定时任务会定时检查当前时间与副本的 lastCaughtUpTimeMs 差值是否大于参数`replica.lag.time.max.ms` 指定的值。

Kafka源码注释中说明了一般有两种情况会导致副本失效：

- follower副本进程卡住，在一段时间内根本没有向leader副本发起同步请求，比如频繁的Full GC。
- follower副本进程同步过慢，在一段时间内都无法追赶上leader副本，比如I/O开销过大。

### ISR的伸缩

Kafka 在启动的时候会开启两个与 ISR 相关的定时任务，名称分别为“isr-expiration”和“isr-change-propagation”。isr-expiration任务会周期性地检测每个分区是否需要缩减其ISR集合。这个周期和`replica.lag.time.max.ms`参数有关，大小是这个参数值的一半，默认值为5000ms。当检测到ISR集合中有失效副本时，就会收缩ISR集合

如果某个分区的ISR集合发生变更，则会将变更后的数据记录到 ZooKeeper 对应的`/brokers/topics/＜topic＞/partition/＜parititon＞/state`节点中。节点中的数据示例如下：

![image-20210929150432809](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210929150432809.png)

- controller_epoch: 当前kafka控制器的epoch
- leader: 当前分区leader副本所在的broker的id编号
- version: 版本号（当前版本固定为1）
- leader_epoch：标识当前分区leader纪元
- isr: 标识变更后ISR列表

### LEO与HW

整个消息追加的过程可以概括如下

1. 生产者客户端发送消息至leader副本（副本1）中。
2. 消息被追加到leader副本的本地日志，并且会更新日志的偏移量
3. follower副本（副本2和副本3）向leader副本请求同步数据。
4. leader副本所在的服务器读取本地日志，并更新对应拉取的follower副本的信息。
5. leader副本所在的服务器将拉取结果返回给follower副本
6. follower副本收到leader副本返回的拉取结果，将消息追加到本地日志中，并更新日志的偏移量信息

### Leader Epoch的介入

follower副本重新上线的时候，通过HW+LeaderEpoch去判断是否需要截断HW到LEO的日志

### 为什么不支持读写分离

没必要，不会带来特别大的提升，而且增加了复杂度。

目前的模型已经可以很好的负载到各个节点上了，分区副本均匀分配到各个节点上。

## 日志同步机制

日志同步机制的一个基本原则就是：如果告知客户端已经成功提交了某条消息，那么即使 leader宕机，也要保证新选举出来的leader中能够包含这条消息。

## 可靠性分析

首先是`acks`，选个1就差不多了

再是配置好`retries`跟`retry.backoff.ms`参数，用于设定重试次数已经重试之间的时间间隔

`min.insync.replicas`定义最少要同步的副本数

`unclean.leader.election.enable`最好是false，使用了OSR的副本会丢失无法预估的消息

除了broker端的配置意外，消费的逻辑处理也会有相应的影响。

最好`enable.auto.commit`设置为false，通过手动提交位移是最保险的

> 提交的位移是下次要拉取的offset，所以提交的值是上次拉取的最后的offset+1

