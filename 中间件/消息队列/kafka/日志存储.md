# 日志存储

1. kafka是怎么存储日志的
2. 为什么要这样存储，有什么优势又有什么劣势

## 文件目录布局

不考虑多副本的情况，一个分区对应一个日志（Log）。为了防止 Log 过大，Kafka又引入了日志分段（LogSegment）的概念，将Log切分为多个LogSegment，相当于一个巨型文件被平均分配为多个相对较小的文件，这样也便于消息的维护和清理。

Log和LogSegment也不是纯粹物理意义上的概念，Log在物理上只以文件夹的形式存储，而每个LogSegment对应磁盘上的一个日志文件和两个索引文件，以及可能的其他文件（比如以".txnindex"为后缀的事务索引文件）

![image-20210923100928971](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210923100928971.png)



向Log中追加消息时是顺序写入的，只有最后一个LogSegment才能执行写入操作，在此之前所有的LogSegment都不能写入数据。



为了便于消息的检索，每个LogSegment中的日志文件（以".log"为文件后缀）都有对应的两个索引文件：

- 偏移量索引文件（以".index"为文件后缀）
- 时间戳索引文件（以".timeindex"为文件后缀）

每个LogSegment都有一个基准偏移量baseOffset，用来表示当前LogSegment中第一条消息的offset。

## 日志格式的演变

### v0版本

![image-20210923114154209](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210923114154209.png)

### v1版本

相比v0版本增加了一个timestamp字段

attributes字段增加了一个标志位，第4位：0表示timestamp类型为CreateTime，1表示类型为LogAppendTime。

timestamp类型由broker端参数`log.message.timestamp.type`来配置，默认值为CreateTime

![image-20210923114220726](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210923114220726.png)

### 消息压缩

常见的压缩算法是数据量越大压缩效果越好，kafka实现压缩的方式是将多条消息一起进行压缩，这样可以保证较好的压缩效果。

一般情况下，生产者发送的压缩数据在broker中也是保持压缩状态进行存储的，消费者从服务端获取也是压缩的消息，消费者在处理消息之前才会解压消息，这样保持了端对端的压缩。

kafka日志通过参数`compression.type`来配置，默认值为`producer`，表示保留生产者使用的压缩方式。

当消息压缩时，是将整个消息集进行压缩作为内层消息（inner message），而内层消息整体作为外层（wrapper message）的value

压缩后外层消息的key为null，value字段中保存的是多条压缩消息。

当生产者创建压缩消息的时候，对内部压缩消息设置的offset从0开始为每个内部消息分配offset

![image-20210923133914046](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210923133914046.png)

![image-20210923134216061](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210923134216061.png)

其实每个从生产者发出的消息集中的消息offset都是从0开始的，对offset的转换是在服务端进行的。

当消费者消费这个消息集的时候，首先解压缩整个消息集，然后找到内层消息中最后一条消息的inner offset

根据如下公式找到内层消息中最后一条消息前面的消息的absolute offset

- RO：Relative Offset
- IO：Inner Offset
- AO：Absolute Offset

```
RO = IO_of_a_message - IO_of_the_last_message
AO = AO_Of_Last_Inner_message + RO
```

对于压缩的情况
外层消息的timestamp设置：

- 如果timestamp类型为createTime，那么设置的是内层消息中的最大的时间戳
- 如果timestamp类型为logAppendTime，那么设置的是kafka服务器当前的时间戳

内层消息的timestamp设置为:

- 如果外层消息的timestamp类型为createTime, 那么设置的是生产者创建消息时的时间戳
- 如果外层消息的timestamp类型为logAppendTime,那么内层消息的时间戳都会被忽略

### 变长字段

从Kafka0.11.0版本开始使用消息格式版本为v2,引入了变长整型(Varints)和ZigZag编码

### v2版本

v2版本消息集称为Record Batch,而不是先前的Message Set,其内部也包含了一条或多条消息.

在消息压缩的情形下,Record Batch Header(first offset到records count字段)是不被压缩的

![image-20210924111422058](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210924111422058.png)

## 日志索引

日志分段文件达到一定的条件时需要进行切分，那么其对应的索引文件也需要进行切分。

日志分段文件切分包含以下几个条件，满足其中一个即可

1. 当前日志分段文件的大小超过了 broker 端参数`log.segment.bytes` 配置的值。`log.segment.bytes`参数的默认值为1073741824，即1GB。
2. 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于 `log.roll.ms`或`log.roll.hours`参数配置的值。如果同时配置了`log.roll.ms`和`log.roll.hours`参数，那么`log.roll.ms`的优先级高。默认情况下，只配置了`log.roll.hours`参数，其值为168，即7天。
3. 偏移量索引文件或时间戳索引文件的大小达到broker端参数`log.index.size.max.bytes`配置的值。`log.index.size.max.bytes`的默认值为10485760，即10MB。
4. 追加的消息的偏移量与当前日志分段的偏移量之间的差值大于Integer.MAX_VALUE，即要追加的消息的偏移量不能转变为相对偏移量（offset-baseOffset＞Integer.MAX_VALUE）

### 偏移量索引

偏移量索引项格式： 8个字节，分为两个部分

1. relativeOffset： 相对偏移量，表示消息相对于baseOffset的偏移量，占用4个字节，当前索引文件的文件名为baseOffset的值
2. position：物理地址，消息在日志分段文件中对应的物理位置，占用4个字节

![image-20210924155207024](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210924155207024.png)

在上面日志分段文件切分的第四个条件，追加消息的偏移量与当前日志分段的偏移量之间的差值大于Integer.MAX_VALUE。如果超过了这个值，relativeOffset就不能用4个字节来表示了。

查找日志分段是利用跳跃表的结构；

kafka的每个日志对象使用了ConcurrentSkipListMap来保存各个日志分段，每个日志分段的baseOffset作为key，这样可以根据指定偏移量来快速定位到消息所在的日志分段

![image-20210924163124530](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210924163124530.png)

```java
ConcurrentSkipListMap<Long, Integer> segmentMap = new ConcurrentSkipListMap<>();
        segmentMap.put(0L, 123);
        segmentMap.put(122L, 124);
        segmentMap.put(251L, 125);
        segmentMap.put(378L, 126);
        segmentMap.put(522L, 127);

        Map.Entry<Long, Integer> longIntegerEntry = segmentMap.lowerEntry(268L);
        System.out.println(longIntegerEntry);
        // output: 251=125
```

> Kafka强制要求索引文件大小必须是索引项大小的整数倍，对于偏移量索引文件而言，必须为8的整数倍。

### 时间戳索引

时间戳索引项格式，每个索引项占用12个字节

1. timestamp：当前日志分段最大的时间戳
2. relativeOffset：时间戳所对应消息的相对偏移量

![image-20210924164121296](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210924164121296.png)

> 与偏移量索引文件相似，时间戳索引文件大小必须是索引项大小（12B）的整倍数

找出指定时间戳targetTimestamp=1526384718288开始的消息的步骤

1. 将targetTimestamp和每个日志分段中的最大时间戳largestTimestamp逐一对比，直到找到不小于 targetTimeStamp 的 largestTimeStamp 所对应的日志分段。日志分段中的largestTimeStamp的计算是先查询该日志分段所对应的时间戳索引文件，找到最后一条索引项，若最后一条索引项的时间戳字段值大于0，则取其值，否则取该日志分段的最近修改时间。
2. 找到相应的日志分段之后，在时间戳索引文件中使用二分查找算法查找到不大于targetTimeStamp的最大索引项，即[1526384718283，28]，如此便找到了一个相对偏移量28。
3. 在偏移量索引文件中使用二分算法查找到不大于28的最大索引项，即[26，838]。
4. 从步骤1中找到日志分段文件中的838的物理位置开始查找不小于targetTimeStamp的消息。

## 日志清理

kafka提供两种日志清理策略

1. 日志删除（Log Retention）：按照一定的保留策略直接删除不符合条件的日志分段
2. 日志压缩（Log Compaction）：针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本

可以通过broker端参数`log.cleanup.policy`设置日志清理策略，此参数的默认值为“delete”。

### 日志删除

在Kafka的日志管理器中会有一个专门的日志删除任务来周期性地检测和删除不符合保留条件的日志分段文件，这个周期可以通过broker端参数`log.retention.check.interval.ms`来配置，默认值为300000，即5分钟

日志分段的保留策略有3种：基于时间的保留策略、基于日志大小的保留策略和基于日志起始偏移量的保留策略

#### 基于时间

日志删除任务会检查当前日志文件中是否有保留时间超过阈值（retentionMs）来寻找可删除的日志分段文件集合（deletableSegments），默认情况下配置了`log.retention.hours`，取值为168，即为7天

![image-20210924173607363](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210924173607363.png)

查找过期的日志分段文件，是根据日志分段中最大的时间戳largestTimestamp来计算。

若待删除的日志分段总数等于所有的分段日志数量，说明所有日志都过期了，但是日志文件中需要一个分段用于接收消息的写入，必须保证有一个活跃的日志分段activeSegment，这种情况下会切分出一个新的日志段作为activeSegment，然后执行删除操作

删除分段时，会先对Log对象中维护的日志分段的跳跃表中删除待删除的日志分段，保证没有线程对这些日志分段进行读取操作。然后将日志分段对应的文件添加上".deleted"后缀，然后通过`delete-file`的延迟任务来删除这些以".deleted"文件

#### 基于日志大小

`log.retention.bytes`配置的是Log中所有日志文件的总大小，默认值为-1，表示无限大。

计算日志文件的总大小size和retention的差值diff

![image-20210926095931406](https://raw.githubusercontent.com/echisan/fiweofjaawef/main/img/image-20210926095931406.png)

#### 基于日志起始偏移量

logStartOffset等于第一个日志分段的baseOffset，但不是绝对的，因为这个值是可以通过DeleteRecordRequest、kafka-delete-records.sh等方式去修改。

基于日志起始偏移量的保留策略的判断依据是某日志分段的下一个日志分段的起始偏移量baseOffset 是否小于等于logStartOffset，若是，则可以删除此日志分段。

### 日志压缩

Kafka中的Log Compaction是指在默认的日志删除（Log Retention）规则之外提供的一种清理过时数据的方式。

og Compaction对于有相同key的不同value值，只保留最后一个版本。

每个日志目录下都有一个名为“cleaner-offest-checkpoint”文件，是清理检查点文件，用于记录每个主题每个分区中已清理的偏移量。

## 磁盘存储

磁盘顺序写入，零拷贝

